---
title: In CDP, change the collection in Infra Solr used by Ranger Audit from
  HDFS to OS local file system, and set TTL.
date: 2021-07-13T10:33:59.005Z
summary: "**After using it for a period of time, because the data generated by
  Ranger Audit in Infra Solr becomes huge, the `ranger_audits` collection in
  Infra Solr often has problems.**


  \r

  \r

  I haven't got a comprehensive understanding of the details behind the scene,
  but in general, from the experience of people around, our best approach is to
  change the `ranger_audits` collection from HDFS backend to OS local File
  system backend.

  And set the ttl of the document in the collection to a smaller value."
draft: true
featured: false
authors:
  - admin
tags:
  - Solr
categories:
  - Big Data
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
---
Recently, I started to learn Solr related knowledge and handle Solr cases opened by clients.

It has to be said that in CDP Private Cloud Base, currently (the current latest version is V7.1.6), some integrations between Ranger Audit and Infra Solr have obviously not undergone rigorous performance testing.

Many customers have encountered problems similar to the following:


**After using it for a period of time, because the data generated by Ranger Audit in Infra Solr becomes huge, the `ranger_audits` collection in Infra Solr often has problems.**



I haven't got a comprehensive understanding of the details behind the scene, but in general, from the experience of people around, our best approach is to change the `ranger_audits` collection from HDFS backend to OS local File system backend.
And set the ttl of the document in the collection to a smaller value.

## Purpose of this article

This article records the steps of how to operate the steps mentioned above.